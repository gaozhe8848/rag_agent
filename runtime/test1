python main.py
/Users/zhecheng/Developer/py/rag/.venv/lib/python3.14/site-packages/langchain_core/_api/deprecation.py:26: UserWarning: Core Pydantic V1 functionality
 isn't compatible with Python 3.14 or greater.                                                                                                          from pydantic.v1.fields import FieldInfo as FieldInfoV1
USER_AGENT environment variable not set, consider setting it to identify your requests.
================================ Human Message =================================

What is the standard method for Task Decomposition?

Once you get the answer, look up common extensions of that method.
================================== Ai Message ==================================
Tool Calls:
  retrieve_context (call_zBG1P0otIpw6hI98j6vRC5cv)
 Call ID: call_zBG1P0otIpw6hI98j6vRC5cv
  Args:
    query: What is the standard method for Task Decomposition?
================================= Tool Message =================================
Name: retrieve_context

Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}
Content: Task decomposition can be done (1) by LLM with simple prompting like "Steps for XYZ.\n1.", "What are the subgoals for achieving XYZ?", (2) by
 using task-specific instructions; e.g. "Write a story outline." for writing a novel, or (3) with human inputs.                                       Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach
 utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.                                 Self-Reflection#

Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}
Content: Component One: Planning#
A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.
Task Decomposition#
Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instr
ucted to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.                                                 Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multip
le thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.                                                           ================================== Ai Message ==================================
Tool Calls:
  retrieve_context (call_qhpdaEa1xKZiy4jSW0cF8Kxc)
 Call ID: call_qhpdaEa1xKZiy4jSW0cF8Kxc
  Args:
    query: common extensions of the standard method of Task Decomposition
================================= Tool Message =================================
Name: retrieve_context

Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}
Content: Task decomposition can be done (1) by LLM with simple prompting like "Steps for XYZ.\n1.", "What are the subgoals for achieving XYZ?", (2) by
 using task-specific instructions; e.g. "Write a story outline." for writing a novel, or (3) with human inputs.                                       Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach
 utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.                                 Self-Reflection#

Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}
Content: Component One: Planning#
A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.
Task Decomposition#
Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instr
ucted to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.                                                 Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multip
le thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.                                                           ================================== Ai Message ==================================

The standard method for Task Decomposition is the Chain of Thought (CoT) prompting technique. In CoT, the model is instructed to "think step by step,"
 breaking down complex tasks into smaller, more manageable steps. This improves performance on challenging tasks and also offers insight into the model’s reasoning process.                                                                                                                                
Common extensions of this method include:

1. Tree of Thoughts (ToT): This extends CoT by allowing multiple possible reasoning paths at each step, effectively building a tree structure of poten
tial solutions. Search methods like breadth-first search (BFS) or depth-first search (DFS) can be used to explore this tree, and evaluation is done using classifiers or majority voting.                                                                                                                   
2. LLM+P (LLM plus Planning): In this approach, task decomposition is outsourced to a classical planner via an interface like PDDL (Planning Domain De
finition Language). The process involves translating problems into PDDL, generating plans with a planner, and translating results back into natural language.                                                                                                                                               
Other methods involve using task-specific instructions or human inputs for decomposition, depending on the application context.